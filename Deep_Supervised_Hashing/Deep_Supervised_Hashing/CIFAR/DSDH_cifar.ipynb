{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from network_cifar import *\n",
    "from tools_cifar import *\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "\n",
    "# DSDH(NIPS2017)\n",
    "# paper [Deep Supervised Discrete Hashing](https://papers.nips.cc/paper/6842-deep-supervised-discrete-hashing.pdf)\n",
    "# code [DSDH_PyTorch](https://github.com/TreezzZ/DSDH_PyTorch)\n",
    "\n",
    "def get_config():\n",
    "    config = {\n",
    "        \"alpha\": 1,\n",
    "        \"nu\": 1,\n",
    "        \"mu\": 1,\n",
    "        \"eta\": 55,\n",
    "        \"dcc_iter\": 10,\n",
    "        # \"optimizer\":{\"type\":  optim.SGD, \"optim_params\": {\"lr\": 0.05, \"weight_decay\": 10 ** -5}, \"lr_type\": \"step\"},\n",
    "        \"optimizer\": {\"type\": optim.RMSprop, \"optim_params\": {\"lr\": 1e-5, \"weight_decay\": 10 ** -5}, \"lr_type\": \"step\"},\n",
    "        \"info\": \"[DSDH]\",\n",
    "        \"resize_size\": 256,\n",
    "        \"crop_size\": 224,\n",
    "        \"batch_size\": 64,\n",
    "        \"net\": AlexNet,\n",
    "        # \"net\":ResNet,\n",
    "        # \"dataset\": \"cifar10\",\n",
    "        \"dataset\": \"cifar10-1\",\n",
    "        # \"dataset\": \"pathmnist\",\n",
    "        \"epoch\": 150,\n",
    "        \"test_map\": 15,\n",
    "        # \"save_path\": \"save/DSDH\",\n",
    "        # \"device\":torch.device(\"cpu\"),\n",
    "        \"device\": torch.device(\"cuda:1\"),\n",
    "        \"bit_list\": [48],\n",
    "    }\n",
    "    config = config_dataset(config)\n",
    "    return config\n",
    "\n",
    "\n",
    "class DSDHLoss(torch.nn.Module):\n",
    "    def __init__(self, config, bit):\n",
    "        super(DSDHLoss, self).__init__()\n",
    "        self.U = torch.zeros(bit, config[\"num_train\"]).float().to(config[\"device\"])\n",
    "        self.B = torch.zeros(bit, config[\"num_train\"]).float().to(config[\"device\"])\n",
    "        self.Y = torch.zeros(config[\"n_class\"], config[\"num_train\"]).float().to(config[\"device\"])\n",
    "\n",
    "    def forward(self, u, y, ind, config):\n",
    "\n",
    "        self.U[:, ind] = u.t().data\n",
    "        self.Y[:, ind] = y.t()\n",
    "\n",
    "        # self.updateBandW(config[\"device\"])\n",
    "\n",
    "        inner_product = u @ self.U * 0.5\n",
    "        s = (y @ self.Y > 0).float()\n",
    "\n",
    "        likelihood_loss = (1 + (-inner_product.abs()).exp()).log() + inner_product.clamp(min=0) - s * inner_product\n",
    "\n",
    "        likelihood_loss = likelihood_loss.mean()\n",
    "\n",
    "        # Classification loss\n",
    "        cl_loss = (y.t() - self.W.t() @ self.B[:, ind]).pow(2).mean()\n",
    "\n",
    "        # Regularization loss\n",
    "        reg_loss = self.W.pow(2).mean()\n",
    "\n",
    "        loss = likelihood_loss + config[\"mu\"] * cl_loss + config[\"nu\"] * reg_loss\n",
    "        return loss\n",
    "\n",
    "    def updateBandW(self, device):\n",
    "        B = self.B\n",
    "        for dit in range(config[\"dcc_iter\"]):\n",
    "            # W-step\n",
    "            W = torch.inverse(B @ B.t() + config[\"nu\"] / config[\"mu\"] * torch.eye(bit).to(device)) @ B @ self.Y.t()\n",
    "\n",
    "            for i in range(B.shape[0]):\n",
    "                P = W @ self.Y + config[\"eta\"] / config[\"mu\"] * self.U\n",
    "                p = P[i, :]\n",
    "                w = W[i, :]\n",
    "                W_prime = torch.cat((W[:i, :], W[i + 1:, :]))\n",
    "                B_prime = torch.cat((B[:i, :], B[i + 1:, :]))\n",
    "                B[i, :] = (p - B_prime.t() @ W_prime @ w).sign()\n",
    "\n",
    "        self.B = B\n",
    "        self.W = W\n",
    "\n",
    "\n",
    "def train_val(config, bit):\n",
    "    device = config[\"device\"]\n",
    "    train_loader, test_loader, dataset_loader, num_train, num_test, num_dataset = get_data(config)\n",
    "    config[\"num_train\"] = num_train\n",
    "    net = config[\"net\"](bit).to(device)\n",
    "\n",
    "    optimizer = config[\"optimizer\"][\"type\"](net.parameters(), **(config[\"optimizer\"][\"optim_params\"]))\n",
    "\n",
    "    criterion = DSDHLoss(config, bit)\n",
    "\n",
    "    Best_mAP = 0\n",
    "\n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        criterion.updateBandW(config[\"device\"])\n",
    "        current_time = time.strftime('%H:%M:%S', time.localtime(time.time()))\n",
    "\n",
    "        print(\"%s[%2d/%2d][%s] bit:%d, dataset:%s, training....\" % (\n",
    "            config[\"info\"], epoch + 1, config[\"epoch\"], current_time, bit, config[\"dataset\"]), end=\"\")\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        for image, label, ind in train_loader:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            u = net(image)\n",
    "\n",
    "            loss = criterion(u, label.float(), ind, config)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print(\"\\b\\b\\b\\b\\b\\b\\b loss:%.3f\" % (train_loss))\n",
    "\n",
    "        if (epoch + 1) % config[\"test_map\"] == 0:\n",
    "            Best_mAP = validate(config, Best_mAP, test_loader, dataset_loader, net, bit, epoch, num_dataset)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = get_config()\n",
    "    print(config)\n",
    "    for bit in config[\"bit_list\"]:\n",
    "        train_val(config, bit)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
